# 图片爬虫工具

这是一个用于从百度图片和必应图片下载图片的爬虫工具。支持图片验证、断点续传、日志记录等功能。

## 目录结构

```
.
├── README.md                 # 项目说明文档
├── requirements.txt          # 项目依赖
├── baidu_crawler.py         # 百度图片爬虫
├── bing_crawler.py          # 必应图片爬虫
├── multi_crawler.py         # 多线程爬虫
├── logs/                    # 日志文件目录
│   └── *.log               # 运行日志文件
├── downloads/               # 下载的图片目录
│   ├── baidu_*/           # 百度图片保存目录
│   └── bing_*/            # 必应图片保存目录
├── debug_html/             # 调试文件目录
│   ├── error_*.html       # 错误页面HTML
│   └── error_*.png        # 错误页面截图
└── records/                # 下载记录目录
    ├── baidu_*_downloads.json  # 百度下载记录
    └── bing_*_downloads.json   # 必应下载记录
```

## 功能特点

1. 图片下载
   - 支持百度图片和必应图片下载
   - 自动跳过已下载的图片
   - 支持断点续传
   - 显示下载进度和预计剩余时间

2. 图片验证
   - 验证图片尺寸（最小512x512）
   - 检测并处理裂图
   - 自动重试下载失败的图片

3. 日志记录
   - 详细的运行日志
   - 记录下载速度、文件大小
   - 记录错误和异常情况

4. 错误处理
   - 保存错误页面的HTML和截图
   - 记录详细的错误信息
   - 自动跳过问题图片

5. 多线程支持
   - 支持并发爬取多个关键词
   - 可配置最大线程数
   - 自动管理线程池

## 使用方法

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 单线程运行

```bash
# 下载百度图片 （可以去代码里最后一行修改要下载的关键词 和 下载的数量 ）
python baidu_crawler.py

# 下载必应图片 （可以去代码里最后一行修改要下载的关键词 和 下载的数量）
python bing_crawler.py
```

### 3. 多线程运行

```bash
# 使用百度搜索引擎，最大3个线程，每个关键词下载100张图片
python multi_crawler.py --keywords "泥土" "石头" "沙子" --num_images 100 --max_workers 3 --engine baidu

# 使用必应搜索引擎，最大5个线程，每个关键词下载50张图片
python multi_crawler.py --keywords "泥土" "石头" "沙子" --num_images 50 --max_workers 5 --engine bing
```

多线程参数说明：
- `--keywords`: 要搜索的关键词列表（必需参数）
- `--num_images`: 每个关键词要下载的图片数量（默认：100）
- `--max_workers`: 最大线程数（默认：3）
- `--engine`: 搜索引擎选择，可选 'baidu' 或 'bing'（默认：'baidu'）

## 配置说明

1. 图片保存
   - 图片保存在 `downloads` 目录下
   - 按搜索引擎和关键词分类存储
   - 自动创建目录结构

2. 日志记录
   - 日志文件保存在 `logs` 目录
   - 文件名包含时间戳和关键词
   - 同时输出到控制台和文件

3. 下载记录
   - 记录保存在 `records` 目录
   - JSON格式存储下载信息
   - 包含URL、文件名、下载时间

4. 调试信息
   - 错误页面保存在 `debug_html` 目录
   - 包含HTML源码和截图
   - 方便排查问题

## 注意事项

1. 运行环境
   - 需要安装Chrome浏览器
   - 需要安装ChromeDriver
   - Python 3.6+ 环境

2. 网络要求
   - 需要稳定的网络连接
   - 建议使用代理或VPN
   - 注意下载频率限制

3. 存储空间
   - 确保有足够的磁盘空间
   - 定期清理日志和调试文件
   - 注意图片存储位置

4. 多线程使用建议
   - 建议将 `max_workers` 设置为 CPU 核心数的 1-2 倍
   - 过多的线程可能会导致网络拥塞或触发反爬虫机制
   - 根据网络条件适当调整线程数

## 常见问题

1. 裂图处理
   - 自动检测裂图URL
   - 刷新页面重试
   - 最多重试3次

2. 下载失败
   - 检查网络连接
   - 查看错误日志
   - 检查存储空间

3. 性能优化
   - 调整等待时间
   - 控制并发数量
   - 优化存储结构

4. 多线程问题
   - 如果遇到网络问题，可以适当减少线程数
   - 适当设置 `num_images` 参数，避免一次下载过多图片
   - 建议使用稳定的网络连接
