# 图片爬虫工具

这是一个用于从百度图片和必应图片下载图片的爬虫工具。支持图片验证、断点续传、日志记录等功能。

## 目录结构

```
.
├── README.md                 # 项目说明文档
├── requirements.txt          # 项目依赖
├── baidu_crawler.py         # 百度图片爬虫
├── bing_crawler.py          # 必应图片爬虫
├── logs/                    # 日志文件目录
│   └── *.log               # 运行日志文件
├── downloads/               # 下载的图片目录
│   ├── baidu_*/           # 百度图片保存目录
│   └── bing_*/            # 必应图片保存目录
├── debug_html/             # 调试文件目录
│   ├── error_*.html       # 错误页面HTML
│   └── error_*.png        # 错误页面截图
└── records/                # 下载记录目录
    ├── baidu_*_downloads.json  # 百度下载记录
    └── bing_*_downloads.json   # 必应下载记录
```

## 功能特点

1. 图片下载
   - 支持百度图片和必应图片下载
   - 自动跳过已下载的图片
   - 支持断点续传
   - 显示下载进度和预计剩余时间

2. 图片验证
   - 验证图片尺寸（最小512x512）
   - 检测并处理裂图
   - 自动重试下载失败的图片

3. 日志记录
   - 详细的运行日志
   - 记录下载速度、文件大小
   - 记录错误和异常情况

4. 错误处理
   - 保存错误页面的HTML和截图
   - 记录详细的错误信息
   - 自动跳过问题图片

## 使用方法

1. 安装依赖
```bash
pip install -r requirements.txt
```

2. 运行爬虫
```bash
# 下载百度图片 （可以去代码里最后一行修改要下载的关键词 和 下载的数量 ）
python baidu_crawler.py

# 下载必应图片 （可以去代码里最后一行修改要下载的关键词 和 下载的数量）
python bing_crawler.py
```

## 配置说明

1. 图片保存
   - 图片保存在 `downloads` 目录下
   - 按搜索引擎和关键词分类存储
   - 自动创建目录结构

2. 日志记录
   - 日志文件保存在 `logs` 目录
   - 文件名包含时间戳和关键词
   - 同时输出到控制台和文件

3. 下载记录
   - 记录保存在 `records` 目录
   - JSON格式存储下载信息
   - 包含URL、文件名、下载时间

4. 调试信息
   - 错误页面保存在 `debug_html` 目录
   - 包含HTML源码和截图
   - 方便排查问题

## 注意事项

1. 运行环境
   - 需要安装Chrome浏览器
   - 需要安装ChromeDriver
   - Python 3.6+ 环境

2. 网络要求
   - 需要稳定的网络连接
   - 建议使用代理或VPN
   - 注意下载频率限制

3. 存储空间
   - 确保有足够的磁盘空间
   - 定期清理日志和调试文件
   - 注意图片存储位置

## 常见问题

1. 裂图处理
   - 自动检测裂图URL
   - 刷新页面重试
   - 最多重试3次

2. 下载失败
   - 检查网络连接
   - 查看错误日志
   - 检查存储空间

3. 性能优化
   - 调整等待时间
   - 控制并发数量
   - 优化存储结构
